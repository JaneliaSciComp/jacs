package org.janelia.it.jacs.compute.service.fly;

import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileWriter;
import java.util.*;

import org.apache.log4j.Logger;
import org.janelia.it.jacs.compute.access.large.LargeOperations;
import org.janelia.it.jacs.compute.api.*;
import org.janelia.it.jacs.compute.engine.data.IProcessData;
import org.janelia.it.jacs.compute.engine.service.IService;
import org.janelia.it.jacs.compute.engine.service.ServiceException;
import org.janelia.it.jacs.compute.service.common.ProcessDataHelper;
import org.janelia.it.jacs.compute.service.fileDiscovery.FileDiscoveryHelper;
import org.janelia.it.jacs.model.entity.Entity;
import org.janelia.it.jacs.model.entity.EntityConstants;
import org.janelia.it.jacs.model.entity.EntityData;
import org.janelia.it.jacs.model.entity.EntityType;
import org.janelia.it.jacs.model.ontology.OntologyAnnotation;
import org.janelia.it.jacs.model.ontology.types.OntologyElementType;
import org.janelia.it.jacs.model.tasks.Task;
import org.janelia.it.jacs.model.user_data.User;
import org.janelia.it.jacs.shared.utils.EntityUtils;
import org.janelia.it.jacs.shared.utils.StringUtils;

/**
 * This service loads screen scores from *.arnimScoreOutput files generated by Sean's Perl scripts, and organizes the 
 * screen samples into intensity and distribution score folders. 
 *
 * @author <a href="mailto:rokickik@janelia.hhmi.org">Konrad Rokicki</a>
 */
public class ScreenScoresLoadingService implements IService {
	
	private static final boolean DEBUG = false;
	
	public static final String TOP_LEVEL_EVALUATION_FOLDER = "FlyLight Pattern Evaluation";
	public static final String SCORE_ONTOLOGY_NAME = "Expression Pattern Evaluation";

	public static final String MAA_USERNAME = "system";
	public static final String MAA_INTENSITY_NAME = "MAA Intensity Score";
	public static final String MAA_DISTRIBUTION_NAME = "MAA Distribution Score";
	public static final String CA_INTENSITY_NAME = "CA Intensity Score";
	public static final String CA_DISTRIBUTION_NAME = "CA Distribution Score";
	
	public static final int MAX_SCORE = 5;
	
    protected Logger logger;
    protected Task task;
    protected User user;
    protected Date createDate;
    protected EntityBeanLocal entityBean;
    protected ComputeBeanLocal computeBean;
    protected AnnotationBeanLocal annotationBean;
	protected FileDiscoveryHelper helper;
    
    protected EntityType folderType;
    
    // The raw data
    protected Set<String> compartments = new LinkedHashSet<String>();
    
    // Lookup tables for ontology terms used in machine assisted annotation
    protected Entity maaIntensityEnum;
    protected Entity maaDistributionEnum;
    protected Map<Integer,Entity> intValueItems = new HashMap<Integer,Entity>();
    protected Map<Integer,Entity> distValueItems = new HashMap<Integer,Entity>();
    
    protected Set<Long> maskIdsNeedingAnnotations = new HashSet<Long>();
    protected SortedSet<String> loaded = new TreeSet<String>();
    
	protected int numSamples;
	protected int numSamplesMissingData;
	protected int numAnnotationsCreated;
	protected int numAnnotatedMasks;
	
    public void execute(IProcessData processData) throws ServiceException {
    	
        try {
            logger = ProcessDataHelper.getLoggerForTask(processData, this.getClass());
            task = ProcessDataHelper.getTask(processData);
            entityBean = EJBFactory.getLocalEntityBean();
            computeBean = EJBFactory.getLocalComputeBean();
            annotationBean = EJBFactory.getLocalAnnotationBean();
            user = computeBean.getUserByName(ProcessDataHelper.getTask(processData).getOwner());
            createDate = new Date();
            helper = new FileDiscoveryHelper(entityBean, computeBean, user);
            folderType = entityBean.getEntityTypeByName(EntityConstants.TYPE_FOLDER);
            
            String acceptsFilepath = (String)processData.getItem("ACCEPTS_FILE_PATH");
        	if (acceptsFilepath == null) {
        		throw new IllegalArgumentException("ACCEPTS_FILE_PATH may not be null");
        	}

            String outputFilepath = (String)processData.getItem("LOADED_FILE_PATH");
        	if (outputFilepath == null) {
        		throw new IllegalArgumentException("LOADED_FILE_PATH may not be null");
        	}
        	
        	File outputFile = new File(outputFilepath);
        	if (!outputFile.getParentFile().canWrite()) {
        		throw new IllegalArgumentException("Cannot write to output file: "+outputFilepath);
        	}
        	
        	// Read input file
        	Set<String> accepted = readNameFile(new File(acceptsFilepath));
        	
        	// Create top level folder
        	Entity topLevelFolder = populateChildren(createOrVerifyRootEntity(TOP_LEVEL_EVALUATION_FOLDER, user, createDate, true, false));
        	
        	if (!topLevelFolder.getChildren().isEmpty()) {
        		throw new IllegalStateException("Cannot reuse existing top level folder, id="+topLevelFolder);
        	}
        	
        	// Process each screen sample and save off its expression scores for later use
        	
        	LargeOperations largeOp = new LargeOperations();
        	
        	for(Entity sample : entityBean.getEntitiesByTypeName(EntityConstants.TYPE_SCREEN_SAMPLE)) {

        		Specimen specimen = Specimen.createSpecimenFromFullName(sample.getName());
        		if (!accepted.contains(specimen.getSpecimenName())) continue;
        		
        		logger.info("Processing "+sample);
        		
        		// Don't read the score files until we need them
        		Map<String,Score> sampleScores = new HashMap<String,Score>();
        		boolean sampleScoresLoaded = false;
        		
        		// Have to read at least one score file set to get all the compartment names
        		if (compartments.isEmpty()) {
					sampleScoresLoaded = true;
					sampleScores.putAll(getSampleScores(sample));
        		}
        		
        		numSamples++;        		
        		
        		// We need to get all the individual mask images for the sample. This child set might contain extra 
        		// stuff we don't care about, but it will get filtered by the score map in the loop below
        		Map<Long,String> masks = getSampleMaskImages(sample);        		

        		// Get annotations for all mask images
        		Map<Long,List<OntologyAnnotation>> annotMap = getAnnotationMap(masks.keySet());
        		
        		for(Long maskId : masks.keySet()) {
        			String maskName = masks.get(maskId);
        			
        			if (DEBUG) logger.info("  Processing "+maskName);
        			
        			List<OntologyAnnotation> annots = annotMap.get(maskId);
        			if (annots==null) continue;
        			
					String maaIntensity = null;
					String maaDistribution = null;
					String caIntensity = null;
					String caDistribution = null;
					for(OntologyAnnotation annotation : annots) {
						if (ScreenScoresLoadingService.MAA_INTENSITY_NAME.equals(annotation.getKeyString())) {
							maaIntensity = annotation.getValueString();
						}
						else if (ScreenScoresLoadingService.MAA_DISTRIBUTION_NAME.equals(annotation.getKeyString())) {
							maaDistribution = annotation.getValueString();
						}
						else if (ScreenScoresLoadingService.CA_INTENSITY_NAME.equals(annotation.getKeyString())) {
							caIntensity = annotation.getValueString();
						}
						else if (ScreenScoresLoadingService.CA_DISTRIBUTION_NAME.equals(annotation.getKeyString())) {
							caDistribution = annotation.getValueString();
						}
					}	
        			
					if (!StringUtils.isEmpty(maaIntensity) && !StringUtils.isEmpty(maaDistribution)) {
						// The current evaluation
						int mi = getValueFromAnnotation(maaIntensity);
						int md = getValueFromAnnotation(maaDistribution);
						int fi = mi;
						int fd = md;
						
						if (!StringUtils.isEmpty(caIntensity)) {
							fi = getValueFromAnnotation(caIntensity);
						}
						
						if (!StringUtils.isEmpty(caDistribution)) {
							fd = getValueFromAnnotation(caDistribution);
						}
						
						Score score = new Score();
						score.maskId = maskId;
						score.intensity = fi;
	        			score.distribution = fd;
	        			sampleScores.put(maskName,score);
	        			
	        			if (DEBUG) logger.info("    Already annotated: i"+score.intensity+"/d"+score.distribution);
					}
					else {
						// No annotations yet
	        			maskIdsNeedingAnnotations.add(maskId);
	        			
	        			// Lazy load the scores
						if (!sampleScoresLoaded) {
							sampleScoresLoaded = true;
							Map<String,Score> savedScores = new HashMap<String,Score>(sampleScores);
							sampleScores.putAll(getSampleScores(sample));
							sampleScores.putAll(savedScores); // in case we already had some in there
						}
						
						// Update our mask id
	        			Score score = sampleScores.get(maskName);
	        			if (score==null) continue;
	        			score.maskId = maskId;
						
	        			if (DEBUG) logger.info("    Needs annotation: i"+score.intensity+"/d"+score.distribution);
					}
        		}
        		
        		// Now go through the scores for this sample, and hash them into the disk-based map for later use
        		for(String maskName : sampleScores.keySet()) {
        			Score score = sampleScores.get(maskName);
        			if (score==null || score.maskId==null) continue;
        			String key = maskName+"/"+score.intensity+"/"+score.distribution;
        			List<Long> sampleCompIds = (List<Long>)largeOp.getValue(LargeOperations.SCREEN_SCORE_MAP, key);
        			if (sampleCompIds==null) {
        				sampleCompIds = new ArrayList<Long>();
        			}
        			sampleCompIds.add(score.maskId);
        			largeOp.putValue(LargeOperations.SCREEN_SCORE_MAP,key,sampleCompIds);
        		}
        		
        		if (!sampleScores.isEmpty()) {
        			loaded.add(specimen.getSpecimenName());
        		}
        		logger.info("  Processed "+sampleScores.size()+" compartments");
        	}
        	
        	// Get or create score ontology
        	getOrCreateOntology();
    		
        	// Create the folder structure and annotate each sample
        	
        	logger.info("Creating folder structure under "+TOP_LEVEL_EVALUATION_FOLDER);

        	for(final String compartment : compartments) {
        		logger.info("Processing compartment "+compartment);
        		Entity compartmentFolder = verifyOrCreateChildFolder(topLevelFolder, compartment);

            	for(int i=MAX_SCORE; i>=0; i--) {
            		logger.info("  Processing intensity "+i);
            		Entity intValueTerm = intValueItems.get(i);
            		Entity intValueFolder = verifyOrCreateChildFolder(compartmentFolder, "Intensity "+i);
            		
                	for(int d=MAX_SCORE; d>=0; d--) {
                		logger.info("  Processing distribution "+d);	
                		Entity distValueTerm = distValueItems.get(d);
	            		Entity distValueFolder = verifyOrCreateChildFolder(intValueFolder, "Distribution "+d);
	            		
	            		String key = compartment+"/"+i+"/"+d;
	            		List<Long> maskIds = (List<Long>)largeOp.getValue(LargeOperations.SCREEN_SCORE_MAP, key);
	            		if (maskIds!=null) {
		            		logger.info("    Sample count: "+maskIds.size());
		            		
		            		entityBean.addChildren(user.getUserLogin(), distValueFolder.getId(), maskIds, EntityConstants.ATTRIBUTE_ENTITY);
		            		
		            		for(Long maskId : maskIds) {
			            		if (maskIdsNeedingAnnotations.contains(maskId)) {
			            			annotate(maskId, maaIntensityEnum, intValueTerm);
			            			annotate(maskId, maaDistributionEnum, distValueTerm);
			            			numAnnotatedMasks++;
			            		}
		            		}
	            		}
                	}
            	}
        	}
        	
        	logger.info("Processed "+numSamples+" samples, loaded "+loaded.size()+". "+
        			numAnnotationsCreated+" annotations were created. "+numAnnotatedMasks+" mask images were annotated.");

        	logger.info("Writing output to "+outputFile.getAbsolutePath());
        	
        	FileWriter writer = new FileWriter(outputFile);
        	
        	for(String name : loaded) {
        		writer.write(name+"\n");
        	}
        	writer.close();
        	
        } 
        catch (Exception e) {
            throw new ServiceException(e);
        }
    }
    
    protected Map<String,Score> getSampleScores(Entity sample) throws Exception {

    	Map<String,Score> sampleScores = new HashMap<String,Score>();
    	
		populateChildren(sample);
		List<Entity> stacks = sample.getChildrenOfType(EntityConstants.TYPE_ALIGNED_BRAIN_STACK);
		if (stacks.isEmpty()) return sampleScores;
		if (stacks.size()>1) {
			logger.warn("More than one aligned brain stack for "+sample.getName()+"");
		}
		
		// Read main score file
		
		Entity stack = stacks.get(0);
		String stackFilepath = stack.getValueByAttributeName(EntityConstants.ATTRIBUTE_FILE_PATH);
		String scoreFilepath = stackFilepath.substring(0,stackFilepath.indexOf("reg.local"))+"arnimScoreOutput";
		
		Map<String,Score> mainScores = readScoresFile(new File(scoreFilepath));
		
		if (mainScores == null) {
			logger.info("  missing score file");
			return sampleScores;
		}

		sampleScores.putAll(mainScores);
		
		// Read Arnim updates
		
		populateChildren(sample);
		
		Entity patternAnnotation = EntityUtils.findChildWithName(sample, "Pattern Annotation");
		if (patternAnnotation==null) {
			logger.warn("  missing Pattern Annotation folder");
			return sampleScores;
		}
		
		Entity maskAnnotation = EntityUtils.findChildWithName(sample, "Mask Annotation");
		if (maskAnnotation!=null) {
			populateChildren(maskAnnotation);
			for(Entity updateFolder : maskAnnotation.getChildren()) {
				if (updateFolder.getName().startsWith("ArnimUpdate")) {

	        		populateChildren(updateFolder);
	        		Entity suppFiles = EntityUtils.findChildWithName(updateFolder, "supportingFiles");
	        		if (suppFiles==null) {
	        			logger.warn("  missing supportingFiles folder");
	        			continue;
	        		}

	        		populateChildren(suppFiles);
	        		Entity scoreFile = EntityUtils.findChildWithName(suppFiles, "arnimScores.txt");
	        		if (scoreFile==null) {
	        			logger.warn("  missing arnimScores.txt");
	        			continue;
	        		}
	        	
	        		String updateScoreFilepath = scoreFile.getValueByAttributeName(EntityConstants.ATTRIBUTE_FILE_PATH);
	        		Map<String,Score> updateScores = readScoresFile(new File(updateScoreFilepath));

	        		if (updateScores == null) {
	        			logger.info("  missing update score file");
	        			continue;
	        		}
	        		
        			sampleScores.putAll(updateScores);	
				}	
			}
		}
		
		return sampleScores;
    }
    
    protected void getOrCreateOntology() throws Exception {

		Set<Entity> matching = entityBean.getUserEntitiesByName(user.getUserLogin(), SCORE_ONTOLOGY_NAME);
		if (matching.size()>1) {
			throw new Exception("More than one ontology named "+SCORE_ONTOLOGY_NAME);
		}
		
		if (matching.isEmpty()) {
    		logger.info("Creating ontology called '"+SCORE_ONTOLOGY_NAME+"'");
    		
    		Entity ontologyTree = annotationBean.createOntologyRoot(user.getUserLogin(), SCORE_ONTOLOGY_NAME);

        	maaIntensityEnum = newTerm(ontologyTree, MAA_INTENSITY_NAME, "Enum");
        	maaDistributionEnum = newTerm(ontologyTree, MAA_DISTRIBUTION_NAME, "Enum");
        	Entity caIntensityEnum = newTerm(ontologyTree, CA_INTENSITY_NAME, "Enum");
        	Entity caDistributionEnum = newTerm(ontologyTree, CA_DISTRIBUTION_NAME, "Enum");
        	
        	for(int i=MAX_SCORE; i>=0; i--) {
        		Entity intTerm = newTerm(maaIntensityEnum, "i"+i, "EnumItem");
        		Entity distTerm = newTerm(maaDistributionEnum, "d"+i, "EnumItem");
        		intValueItems.put(i, intTerm);
        		distValueItems.put(i, distTerm);
        		newTerm(caIntensityEnum, "i"+i, "EnumItem");
        		newTerm(caDistributionEnum, "d"+i, "EnumItem");
        	}
		}
		else {
			long ontologyId = matching.iterator().next().getId();
			logger.info("Reusing existing ontology called '"+SCORE_ONTOLOGY_NAME+"' (id="+ontologyId+")");
			
			Entity ontologyTree = annotationBean.getOntologyTree(user.getUserLogin(), ontologyId);

			maaIntensityEnum = EntityUtils.findChildWithName(ontologyTree, ScreenScoresLoadingService.MAA_INTENSITY_NAME);
			maaDistributionEnum = EntityUtils.findChildWithName(ontologyTree, ScreenScoresLoadingService.MAA_DISTRIBUTION_NAME);
			
	    	for(int i=ScreenScoresLoadingService.MAX_SCORE; i>=0; i--) {
	    		intValueItems.put(i, EntityUtils.findChildWithName(maaIntensityEnum, "i"+i));
	    		distValueItems.put(i, EntityUtils.findChildWithName(maaDistributionEnum, "d"+i));
	    	}
		}
    }
    
    protected void annotate(Long targetId, Entity key, Entity value) throws ComputeException {
		OntologyAnnotation annotation = new OntologyAnnotation(null, targetId, key.getId(), key.getName(), value.getId(), value.getName());
		annotationBean.createSilentOntologyAnnotation(MAA_USERNAME, annotation);
		numAnnotationsCreated++;
    }
    
    protected Entity newTerm(Entity parent, String name, OntologyElementType type) throws ComputeException {
    	EntityData ed = annotationBean.createOntologyTerm(user.getUserLogin(), parent.getId(), name, type, parent.getMaxOrderIndex()+1);
    	parent.getEntityData().add(ed);
    	return ed.getChildEntity();
    }

    protected Entity newTerm(Entity parent, String name, String type) throws ComputeException {
    	return newTerm(parent, name, OntologyElementType.createTypeByName(type));
    }
    
    protected Map<String,Score> readScoresFile(File scoresFile) throws Exception {
    	
    	Map<String,Score> scores = new HashMap<String,Score>();
    	
    	// The 5 numbers in these files for each compartment should be interpreted as:
        // <intensity 40-threshold> <intensity 10-threshold> <intensity 0-threshold> <distribution-medium-slope> <distribution no-slope>    	
    	// The "official" intensity and distribution values are defined as:
    	// Intensity = <intensity 40-threshold>
    	// Distribution = <distribution medium-slope>
    	// I.e., we should be using the 1st and 4th of the 5 values.
    	
		Scanner scanner = null;
        try {
        	scanner = new Scanner(scoresFile);
            while (scanner.hasNextLine()){
            	
                String[] parts = scanner.nextLine().split(" ");
                int c = 0;
                String num = getCol(parts, c++);
                String compartment = getCol(parts, c++);
                String int40Threshold = getCol(parts, c++);
                String int10Threshold = getCol(parts, c++);
                String int0Threshold = getCol(parts, c++);
                String distMediumSlope = getCol(parts, c++);
                String distNoSlope = getCol(parts, c++);
                Score score = new Score();
            	score.intensity = new Integer(int40Threshold);	
                score.distribution = new Integer(distMediumSlope);
                scores.put(compartment,score);
                compartments.add(compartment);
            }
        }
        catch (FileNotFoundException e) {
        	return null;
        }
        catch (Exception e) {
        	logger.warn("Problem reading score file: "+scoresFile.getAbsolutePath());
        	return scores;
        }
        finally {
        	if (scanner!=null) scanner.close();
        }
        
        return scores;
    }

    protected class Score {
    	Long maskId;
    	Integer distribution;
    	Integer intensity; 
    }

    protected String getCol(String[] cols, int index) {
    	if (index > cols.length-1) return null;
    	return cols[index];
    }
    
    protected Map<Long,String> getSampleMaskImages(Entity sample) {

    	Map<Long,String> childNames = new HashMap<Long,String>();

		populateChildren(sample);
		Entity patternAnnotation = EntityUtils.findChildWithName(sample, "Pattern Annotation");
		if (patternAnnotation!=null) {
			childNames.putAll(entityBean.getChildEntityNames(patternAnnotation.getId()));
		}
		
		Entity maskAnnotation = EntityUtils.findChildWithName(sample, "Mask Annotation");
		if (maskAnnotation!=null) {
			populateChildren(maskAnnotation);
			for(Entity updateFolder : maskAnnotation.getChildren()) {
				if (updateFolder.getName().startsWith("ArnimUpdate")) {
					childNames.putAll(entityBean.getChildEntityNames(updateFolder.getId()));
				}
			}
		}
		
		return childNames;
    }
    
    protected Map<Long,List<OntologyAnnotation>> getAnnotationMap(Collection<Long> entityIds) throws Exception {
		List<Long> maskIds = new ArrayList<Long>(entityIds);
		Map<Long,List<OntologyAnnotation>> annotMap = new HashMap<Long,List<OntologyAnnotation>>();
		for(Entity annotEntity : annotationBean.getAnnotationsForEntities(user.getUserLogin(), maskIds)) {
			OntologyAnnotation annototation = new OntologyAnnotation();
			annototation.init(annotEntity);
			List<OntologyAnnotation> entityAnnots = annotMap.get(annototation.getTargetEntityId());
			if (entityAnnots==null) {
				entityAnnots = new ArrayList<OntologyAnnotation>();
				annotMap.put(annototation.getTargetEntityId(), entityAnnots);
			}
			entityAnnots.add(annototation);
		}
		return annotMap;
    }

    protected Set<String> readNameFile(File nameFile) throws Exception {
    	Set<String> names = new HashSet<String>();
		Scanner scanner = new Scanner(nameFile);
        try {
            while (scanner.hasNextLine()){
            	names.add(scanner.nextLine());
            }
        }
        finally {
        	scanner.close();
        }
        return names;
    }

    protected int getValueFromAnnotation(String annotationValue) {
		return Integer.parseInt(""+annotationValue.charAt(1));
	}
	
    protected int getValueFromFolderName(Entity entity) {
		return getValueFromFolderName(entity.getName());
	}
	
    protected int getValueFromFolderName(String folderName) {
		try {
			return Integer.parseInt(""+folderName.charAt(folderName.length()-1));
		}
		catch (Exception e) {
			logger.error("Error parsing folder name "+folderName+": "+e.getMessage());
		}
		return -1;
	}
    
    protected Entity populateChildren(Entity entity) {
    	if (entity==null || EntityUtils.areLoaded(entity.getEntityData())) return entity;
		EntityUtils.replaceChildNodes(entity, entityBean.getChildEntities(entity.getId()));
		return entity;
    }
    
    protected Entity createOrVerifyRootEntity(String topLevelFolderName, User user, Date createDate, boolean createIfNecessary, boolean loadTree) throws Exception {
        Set<Entity> topLevelFolders = entityBean.getEntitiesByName(topLevelFolderName);
        Entity topLevelFolder = null;
        if (topLevelFolders != null) {
            // Only accept the current user's top level folder
            for (Entity entity : topLevelFolders) {
                if (entity.getUser().getUserLogin().equals(user.getUserLogin())
                        && entity.getEntityType().getName().equals(folderType.getName())
                        && entity.getAttributeByName(EntityConstants.ATTRIBUTE_COMMON_ROOT) != null) {
                    // This is the folder we want, now load the entire folder hierarchy
                    if (loadTree) {
                        topLevelFolder = entityBean.getEntityTree(entity.getId());
                    } else {
                        topLevelFolder = entity;
                    }
                    logger.info("Found existing topLevelFolder common root, name=" + topLevelFolder.getName());
                    break;
                }
            }
        }

        if (topLevelFolder == null && createIfNecessary) {
            logger.info("Creating new topLevelFolder with name=" + topLevelFolderName);
            topLevelFolder = new Entity();
            topLevelFolder.setCreationDate(createDate);
            topLevelFolder.setUpdatedDate(createDate);
            topLevelFolder.setUser(user);
            topLevelFolder.setName(topLevelFolderName);
            topLevelFolder.setEntityType(folderType);
            topLevelFolder.addAttributeAsTag(EntityConstants.ATTRIBUTE_COMMON_ROOT);
            topLevelFolder = entityBean.saveOrUpdateEntity(topLevelFolder);
            logger.info("Saved top level folder as " + topLevelFolder.getId());
        }

        return topLevelFolder;
    }

    protected Entity verifyOrCreateChildFolder(Entity parent, String childName) throws Exception {

        logger.info("Looking for child entity "+childName+" in parent entity "+parent.getId());
        for (EntityData ed : parent.getEntityData()) {
            Entity child = ed.getChildEntity();
            if (child != null && child.getEntityType().getName().equals(folderType.getName()) && child.getName().equals(childName)) {
            	Entity folder = ed.getChildEntity();	
                logger.info("Found folder with id="+folder.getId());
                return folder;
            }
        }
    
        // We need to create a new folder
        Entity child = new Entity();
        child.setCreationDate(createDate);
        child.setUpdatedDate(createDate);
        child.setUser(user);
        child.setName(childName);
        child.setEntityType(folderType);
        child = entityBean.saveOrUpdateEntity(child);
        logger.info("Saved child as "+child.getId());
        addToParent(parent, child, parent.getMaxOrderIndex()+1, EntityConstants.ATTRIBUTE_ENTITY);
    
        return child;
    }

    protected void addToParent(Entity parent, Entity entity, Integer index, String attrName) throws Exception {
        EntityData ed = parent.addChildEntity(entity, attrName);
        ed.setOrderIndex(index);
        entityBean.saveOrUpdateEntityData(ed);
        logger.info("Added "+entity.getEntityType().getName()+"#"+entity.getId()+
        		" as child of "+parent.getEntityType().getName()+"#"+parent.getId());
    }
}
